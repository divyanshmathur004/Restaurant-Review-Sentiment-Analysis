{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD0WaUJfXsI2"
   },
   "source": [
    "# **Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIKw75BUSuLp",
    "outputId": "b5e4e543-7717-4e49-ff73-feb8a66f9faa"
   },
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YniuuWj1TJC9",
    "outputId": "bc93ec25-080d-409a-f197-90e8751bdaa5"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np # linear algebra\n",
    "import numpy\n",
    "import math\n",
    "import pandas as pd # data processing\n",
    "import nltk # Natural Lanauge Toolkit, package used for NLP\n",
    "import re # package to work with regular expressions\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer # CountVectorizer converts text to numerical data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split # spilts existing data into training and testing data\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc, classification_report, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt # low level graph plotting library that helps in visualization\n",
    "import seaborn as sns # visualization library based on matplotlib\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdSb0NSBTOFU"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t' , quoting=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7-SMJG_X11Z"
   },
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWEW4P-RTSiB"
   },
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFCW8QFJUR-J"
   },
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ji9oj1c_UXuq"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pldZ7zliUcTY"
   },
   "outputs": [],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKKmtUCRX7zP"
   },
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZF7ZsWcUeOj"
   },
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-I_ln9OUhEv"
   },
   "outputs": [],
   "source": [
    "corpus =[]\n",
    "for i in range(0,1000):\n",
    "   review =re.sub(pattern='[^a-zA-Z]',repl=' ', string=data['Review'][i])\n",
    "\n",
    "   review = review.lower()\n",
    "   review_words = review.split()\n",
    "   review_words = [word for word in review_words if not word in set(stopwords.words('english'))]\n",
    "\n",
    "   ps= PorterStemmer()\n",
    "   review =[ps.stem(word) for word in review_words]\n",
    "\n",
    "   review = ' '.join(review)\n",
    "   corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSgcdlGxUjMJ"
   },
   "outputs": [],
   "source": [
    "corpus[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffVsrTSpUlQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X =cv.fit_transform(corpus).toarray()\n",
    "y = data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXdL_RCiU6EF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXevMGf1U6o8",
    "outputId": "16d7c631-8aef-4679-f875-0e1137da3b72"
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape, y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz_uP6RRYCOG"
   },
   "source": [
    "# **Data Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_sq2_CMYD2l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCwJbYpuY8Gt"
   },
   "source": [
    "## **Multinomial Naive Bayes Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f2s7XLmU9CB"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiQ9LoUtU_zb"
   },
   "outputs": [],
   "source": [
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Q-A4KksVDjw",
    "outputId": "ffdf3653-cb92-4305-cc6f-42782dfcb2a2"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = accuracy_score(y_test,y_pred)\n",
    "score3 = recall_score(y_test,y_pred)\n",
    "\n",
    "print(\"---------SCORES--------\")\n",
    "print(\"Accuracy score is {}%\".format(round(score1*100,3)))\n",
    "print(\"Precision score is {}%\".format(round(score2*100,3)))\n",
    "print(\"Recall score is {}%\".format(round(score3*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpLjlXgAVEhh",
    "outputId": "a38b09a6-3bcd-4f8e-cf67-4963a4e31c20"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "BBhCfq4TVIvS",
    "outputId": "210970c4-1976-4b76-c932-fdda94e3df80"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize =(10,6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", xticklabels=['Negative','Positive'],yticklabels=['Negative','Positive'])\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Actual Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAmBIfdJYVQE"
   },
   "source": [
    "### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAmm7pcLVKvs",
    "outputId": "7e8cdb51-5a19-4136-8e84-7024a741af23"
   },
   "outputs": [],
   "source": [
    "from ssl import ALERT_DESCRIPTION_HANDSHAKE_FAILURE\n",
    "best_accuracy = 0.0\n",
    "alpha_val = 0.0\n",
    "for i in np.arange(0.1,1.1,0.1):\n",
    "  temp_mnb = MultinomialNB(alpha=i)\n",
    "  temp_mnb.fit(X_train,y_train)\n",
    "  temp_y_pred = temp_mnb.predict(X_test)\n",
    "  score = accuracy_score(y_test,temp_y_pred)\n",
    "  print(\"Accuracy Score for alpha={} is {}%\".format(round(i,1),round(score*100,3)))\n",
    "  if score>best_accuracy:\n",
    "     best_accuracy = score\n",
    "     alpha_val = i\n",
    "print('----------------------------------------------------')\n",
    "print(\"The Best Accuracy Score is {}% with alpha value as {}\".format(round(best_accuracy*100, 2), round(alpha_val, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "_aJIK8o4Z4a1",
    "outputId": "dc778249-3b2b-42e9-ac85-d3c4efe76d72"
   },
   "outputs": [],
   "source": [
    "mnb =MultinomialNB(alpha=0.2)\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaEjKer3aNKm"
   },
   "source": [
    "## **Gaussian Naive Bayes Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwss_a_5aQUZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ULWhYpKbBld"
   },
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6P5ueaPby1A",
    "outputId": "b6a1307d-7916-46a9-b68e-e50fad6c9939"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = accuracy_score(y_test,y_pred)\n",
    "score3 = recall_score(y_test,y_pred)\n",
    "\n",
    "print(\"---------SCORES--------\")\n",
    "print(\"Accuracy score is {}%\".format(round(score1*100,3)))\n",
    "print(\"Precision score is {}%\".format(round(score2*100,3)))\n",
    "print(\"Recall score is {}%\".format(round(score3*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuSNTqtCcQbH",
    "outputId": "b46b266c-56a0-498a-b3a9-cca94a30b746"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgVbWqvHcntW"
   },
   "source": [
    "### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWST0_NTcntX",
    "outputId": "6e337998-805b-4a4f-8d44-0f7f01998c7c"
   },
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0.0\n",
    "alpha_val = 0.0\n",
    "\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    gnb = GaussianNB(var_smoothing=i)\n",
    "    gnb.fit(X_train, y_train)\n",
    "    temp_y_pred = gnb.predict(X_test)\n",
    "    score = accuracy_score(y_test, temp_y_pred)\n",
    "    print(\"Accuracy Score for alpha={} is {}%\".format(round(i, 1), round(score * 100, 3)))\n",
    "    if score > best_accuracy:\n",
    "        best_accuracy = score\n",
    "        alpha_val = i\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print(\"The Best Accuracy Score is {}% with alpha as {}\".format(round(best_accuracy * 100, 2), round(alpha_val, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "jVfUtwwTcntX",
    "outputId": "4820565c-a499-4406-9a60-d93267324e09"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB(var_smoothing=0.1)\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrNOAy9wdSDL"
   },
   "source": [
    "## **Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtxWju9vdSDf"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCqDCYicdSDg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuWPN5d0dSDg"
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLoYBbKodSDh",
    "outputId": "b8696d45-422e-4ffb-fbbd-4523b25ea20e"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = accuracy_score(y_test,y_pred)\n",
    "score3 = recall_score(y_test,y_pred)\n",
    "\n",
    "print(\"---------SCORES--------\")\n",
    "print(\"Accuracy score is {}%\".format(round(score1*100,3)))\n",
    "print(\"Precision score is {}%\".format(round(score2*100,3)))\n",
    "print(\"Recall score is {}%\".format(round(score3*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJKNOjAQdSDh",
    "outputId": "fccdc406-1b48-4dd4-f442-e529033528dc"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D85vKJ7dSDj"
   },
   "source": [
    "### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UbP82-8dSDj",
    "outputId": "d0faed92-746c-4632-d67d-c07ddb4039ee"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "best_C = 0.0\n",
    "\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    lr = LogisticRegression(C=i)  # Use C instead of alpha\n",
    "    lr.fit(X_train, y_train)\n",
    "    temp_y_pred = lr.predict(X_test)\n",
    "    score = accuracy_score(y_test, temp_y_pred)\n",
    "    print(\"Accuracy Score for alpha={} is {}%\".format(round(i, 1), round(score * 100, 3)))\n",
    "    if score > best_accuracy:\n",
    "        best_accuracy = score\n",
    "        best_C = i\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "print(\"The Best Accuracy Score is {}% with alpha value as {}\".format(round(best_accuracy * 100, 2), round(best_C, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "sJDnca3odSDj",
    "outputId": "8f7a6ff7-ec81-40a3-94c1-514811c29787"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cvc7r0reIoi"
   },
   "source": [
    "## **Random Forest Classifier Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkectJ5BeIoj",
    "outputId": "6189ad22-6e2a-4bd4-b222-37d9d6bfcf81"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jegRVQgGeIok"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "an0UQxm5eIok",
    "outputId": "f912efe7-e136-44a6-a350-557636a8a346"
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAWxgpkEeIol",
    "outputId": "c3e7056b-e09a-4444-e132-c4afcfa54492"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = accuracy_score(y_test,y_pred)\n",
    "score3 = recall_score(y_test,y_pred)\n",
    "\n",
    "print(\"---------SCORES--------\")\n",
    "print(\"Accuracy score is {}%\".format(round(score1*100,3)))\n",
    "print(\"Precision score is {}%\".format(round(score2*100,3)))\n",
    "print(\"Recall score is {}%\".format(round(score3*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-5ZbCwCeIol",
    "outputId": "eb8b1e85-2a6e-4d66-88e9-ab25ead6f011"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MjmLi6YeIol"
   },
   "source": [
    "### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJpuphNbeIol",
    "outputId": "877e511b-8f4b-4956-9037-15cbb7579f61"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid you want to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # You can adjust these values\n",
    "    'max_depth': [None, 10, 20],     # You can adjust these values\n",
    "}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = {}\n",
    "\n",
    "# Create the random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Use GridSearchCV to search for the best parameters\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"The Best Accuracy Score is {}%\".format(round(best_accuracy * 100, 2)))\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk3kYYlmeIom",
    "outputId": "e795d7ae-5ce8-4443-da62-933755685f03"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em7eQS70ZHYz"
   },
   "source": [
    "# **Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nU1ma-zyVi_V"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def predict_sentiment(sample_review):\n",
    "    sample_review = re.sub(pattern='[^a-zA-Z]', repl=' ', string=sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    sample_review_words = sample_review.split()\n",
    "    sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "    ps = PorterStemmer()\n",
    "    final_review = [ps.stem(word) for word in sample_review_words]\n",
    "    final_review = ' '.join(final_review)\n",
    "\n",
    "    temp = cv.transform([final_review]).toarray()\n",
    "    return mnb.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the function directly\n",
    "test_review = \"this is a good restaurant\"\n",
    "prediction_result = predict_sentiment(test_review)\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1JeM2FZVkBf",
    "outputId": "0e03618a-ab3f-44db-897d-49e53c0044b6"
   },
   "outputs": [],
   "source": [
    "# Replace the input() function with a specific string\n",
    "sample_review = \"The food was amazing and the service was excellent!\"\n",
    "\n",
    "# The rest of the code remains the same\n",
    "if predict_sentiment(sample_review):\n",
    "  print(\"Positive review\")\n",
    "else:\n",
    "  print(\"Negative review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
